{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Copia de NLP Course - Week 3 Exercise Question.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hipatiaj/NLP_course/blob/master/NLP_Course_Week_3_Exercise_Question.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zX4Kg8DUTKWO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WFiqpouR3ixU",
        "colab_type": "text"
      },
      "source": [
        "## Barajar la data antes de asignar las etiquetas \"0 y 1\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LRmCthy971Nz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bb9aaa05-a20a-497b-a098-24ae472e8331"
      },
      "source": [
        "!pwd"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MSLesB_L7xvG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hmA6EzkQJ5jt",
        "colab": {}
      },
      "source": [
        "import json\n",
        "import tensorflow as tf\n",
        "import csv\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras import regularizers\n",
        "\n",
        "\n",
        "embedding_dim = 100\n",
        "max_length = 16\n",
        "trunc_type='post'\n",
        "padding_type='post'\n",
        "oov_tok = \"<OOV>\"\n",
        "training_size=160000\n",
        "#Your dataset size here. Experiment using smaller values (i.e. 16000), but don't forget to train on at least 160000 to see the best effects\n",
        "test_portion=.1\n",
        "\n",
        "corpus = []\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bM0l_dORKqE0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "outputId": "c8cf05b7-c025-47a2-861c-a28f6a05054c"
      },
      "source": [
        "# Note that I cleaned the Stanford dataset to remove LATIN1 encoding to make it easier for Python CSV reader\n",
        "# You can do that yourself with:\n",
        "# iconv -f LATIN1 -t UTF8 training.1600000.processed.noemoticon.csv -o training_cleaned.csv\n",
        "# I then hosted it on my site to make it easier to use in this notebook\n",
        "\n",
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/laurencemoroney-blog.appspot.com/training_cleaned.csv \\\n",
        "    -O /tmp/training_cleaned.csv\n",
        "\n",
        "num_sentences = 0\n",
        "\n",
        "with open(\"/tmp/training_cleaned.csv\") as csvfile:\n",
        "    reader = csv.reader(csvfile, delimiter=',')\n",
        "    #iterador=iter(reader)\n",
        "    #lista=list(iterador)\n",
        "    #random.shuffle(lista)\n",
        "    for row in reader:\n",
        "      # Your Code here. Create list items where the first item is the text, found in row[5], and the second is the label. Note that the label is a '0' or a '4' in the text. When it's the former, make\n",
        "      # your label to be 0, otherwise 1. Keep a count of the number of sentences in num_sentences\n",
        "        list_item=[]\n",
        "        # YOUR CODE HERE\n",
        "        if row[0]==\"4\":\n",
        "          row[0]=1\n",
        "        else:\n",
        "          row[0]=0\n",
        "        \n",
        "        list_item.append(row[5])\n",
        "        list_item.append(row[0])\n",
        "        \n",
        "        num_sentences = num_sentences + 1\n",
        "        corpus.append(list_item)\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-07-24 16:33:44--  https://storage.googleapis.com/laurencemoroney-blog.appspot.com/training_cleaned.csv\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 108.177.15.128, 173.194.76.128, 2a00:1450:400c:c09::80, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|108.177.15.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 238942690 (228M) [application/octet-stream]\n",
            "Saving to: ‘/tmp/training_cleaned.csv’\n",
            "\n",
            "/tmp/training_clean 100%[===================>] 227.87M  38.8MB/s    in 5.9s    \n",
            "\n",
            "2020-07-24 16:33:50 (38.8 MB/s) - ‘/tmp/training_cleaned.csv’ saved [238942690/238942690]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O22J8Js3SOI9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a39d720d-90bd-4166-b97c-a626880990a8"
      },
      "source": [
        "corpus[-20]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['@myheartandmind jo jen by nemuselo zrovna tÃ© holce ael co nic ', 1]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O9nXJ2Sj8NOB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4b5252a7-e6e0-4106-a442-661ead0b63dd"
      },
      "source": [
        "len(corpus)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1600000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3kxblBUjEUX-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "f7c84b73-4d1e-4f5c-cc5c-9cf1a4034161"
      },
      "source": [
        "print(num_sentences)\n",
        "print(len(corpus))\n",
        "print(corpus[1])\n",
        "\n",
        "# Expected Output:\n",
        "# 1600000\n",
        "# 1600000\n",
        "# [\"is upset that he can't update his Facebook by texting it... and might cry as a result  School today also. Blah!\", 0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1600000\n",
            "1600000\n",
            "[\"is upset that he can't update his Facebook by texting it... and might cry as a result  School today also. Blah!\", 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ohOGz24lsNAD",
        "colab": {}
      },
      "source": [
        "sentences=[]\n",
        "labels=[]\n",
        "random.shuffle(corpus)\n",
        "for x in range(training_size):\n",
        "    sentences.append(corpus[x][0])\n",
        "    labels.append(corpus[x][1])\n",
        "\n",
        "\n",
        "tokenizer = Tokenizer(oov_token=oov_tok )\n",
        "tokenizer.fit_on_texts(sentences)\n",
        "\n",
        "word_index = tokenizer.word_index\n",
        "vocab_size=len(word_index)\n",
        "\n",
        "sequences = tokenizer.texts_to_sequences(sentences)\n",
        "padded = pad_sequences( sequences,maxlen=max_length, padding=\"post\",truncating=\"post\" )\n",
        "\n",
        "split = int(test_portion * training_size)\n",
        "\n",
        "test_sequences = padded[0:split]\n",
        "training_sequences = padded[split:]\n",
        "test_labels = labels[0:split]\n",
        "training_labels = labels[split:]\n",
        "\n",
        "test_labels=np.array(test_labels)\n",
        "training_labels=np.array(training_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H_C02g-Cz6sX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "917128f7-9621-42b1-d081-6cd833afebce"
      },
      "source": [
        "word_index"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'<OOV>': 1,\n",
              " 'i': 2,\n",
              " 'to': 3,\n",
              " 'the': 4,\n",
              " 'a': 5,\n",
              " 'my': 6,\n",
              " 'and': 7,\n",
              " 'you': 8,\n",
              " 'is': 9,\n",
              " 'it': 10,\n",
              " 'for': 11,\n",
              " 'in': 12,\n",
              " 'of': 13,\n",
              " 'me': 14,\n",
              " 'on': 15,\n",
              " 'so': 16,\n",
              " 'have': 17,\n",
              " 'that': 18,\n",
              " 'but': 19,\n",
              " \"i'm\": 20,\n",
              " 'just': 21,\n",
              " 'with': 22,\n",
              " 'at': 23,\n",
              " 'be': 24,\n",
              " 'not': 25,\n",
              " 'was': 26,\n",
              " 'this': 27,\n",
              " 'now': 28,\n",
              " 'up': 29,\n",
              " 'good': 30,\n",
              " 'day': 31,\n",
              " 'all': 32,\n",
              " 'out': 33,\n",
              " 'get': 34,\n",
              " 'like': 35,\n",
              " 'are': 36,\n",
              " 'no': 37,\n",
              " 'go': 38,\n",
              " 'http': 39,\n",
              " 'quot': 40,\n",
              " 'do': 41,\n",
              " 'today': 42,\n",
              " 'too': 43,\n",
              " 'work': 44,\n",
              " \"it's\": 45,\n",
              " 'your': 46,\n",
              " 'going': 47,\n",
              " 'love': 48,\n",
              " 'got': 49,\n",
              " 'lol': 50,\n",
              " 'time': 51,\n",
              " 'back': 52,\n",
              " 'from': 53,\n",
              " 'u': 54,\n",
              " 'one': 55,\n",
              " 'will': 56,\n",
              " 'com': 57,\n",
              " 'what': 58,\n",
              " 'know': 59,\n",
              " 'about': 60,\n",
              " 'we': 61,\n",
              " 'im': 62,\n",
              " 'really': 63,\n",
              " 'am': 64,\n",
              " \"don't\": 65,\n",
              " 'amp': 66,\n",
              " 'had': 67,\n",
              " 'can': 68,\n",
              " 'some': 69,\n",
              " 'see': 70,\n",
              " 'its': 71,\n",
              " \"can't\": 72,\n",
              " 'well': 73,\n",
              " 'if': 74,\n",
              " 'still': 75,\n",
              " '2': 76,\n",
              " 'night': 77,\n",
              " 'new': 78,\n",
              " 'how': 79,\n",
              " 'think': 80,\n",
              " 'want': 81,\n",
              " 'thanks': 82,\n",
              " 'home': 83,\n",
              " 'when': 84,\n",
              " 'as': 85,\n",
              " 'there': 86,\n",
              " 'oh': 87,\n",
              " 'more': 88,\n",
              " 'miss': 89,\n",
              " 'much': 90,\n",
              " 'here': 91,\n",
              " 'off': 92,\n",
              " 'need': 93,\n",
              " 'last': 94,\n",
              " 'an': 95,\n",
              " 'they': 96,\n",
              " 'great': 97,\n",
              " 'morning': 98,\n",
              " 'then': 99,\n",
              " 'tomorrow': 100,\n",
              " 'has': 101,\n",
              " '3': 102,\n",
              " 'been': 103,\n",
              " 'hope': 104,\n",
              " 'twitter': 105,\n",
              " 'or': 106,\n",
              " 'haha': 107,\n",
              " 'her': 108,\n",
              " 'feel': 109,\n",
              " 'again': 110,\n",
              " 'sad': 111,\n",
              " 'he': 112,\n",
              " 'fun': 113,\n",
              " 'sleep': 114,\n",
              " 'wish': 115,\n",
              " 'only': 116,\n",
              " 'bad': 117,\n",
              " 'why': 118,\n",
              " 'happy': 119,\n",
              " 'very': 120,\n",
              " 'right': 121,\n",
              " 'sorry': 122,\n",
              " 'did': 123,\n",
              " 'would': 124,\n",
              " \"i'll\": 125,\n",
              " 'tonight': 126,\n",
              " 'though': 127,\n",
              " 'bit': 128,\n",
              " 'way': 129,\n",
              " 'by': 130,\n",
              " 'them': 131,\n",
              " 'make': 132,\n",
              " 'getting': 133,\n",
              " 'come': 134,\n",
              " 'watching': 135,\n",
              " 'nice': 136,\n",
              " 'gonna': 137,\n",
              " 'over': 138,\n",
              " 'she': 139,\n",
              " 'better': 140,\n",
              " 'should': 141,\n",
              " 'bed': 142,\n",
              " 'wait': 143,\n",
              " 'yeah': 144,\n",
              " \"that's\": 145,\n",
              " 'twitpic': 146,\n",
              " 'could': 147,\n",
              " 'week': 148,\n",
              " 'school': 149,\n",
              " 'people': 150,\n",
              " 'hate': 151,\n",
              " \"i've\": 152,\n",
              " \"didn't\": 153,\n",
              " \"you're\": 154,\n",
              " 'him': 155,\n",
              " 'days': 156,\n",
              " 'hey': 157,\n",
              " 'after': 158,\n",
              " '4': 159,\n",
              " 'even': 160,\n",
              " 'down': 161,\n",
              " 'never': 162,\n",
              " 'dont': 163,\n",
              " 'weekend': 164,\n",
              " 'next': 165,\n",
              " 'awesome': 166,\n",
              " 'were': 167,\n",
              " 'thank': 168,\n",
              " 'yes': 169,\n",
              " 'lt': 170,\n",
              " 'soon': 171,\n",
              " 'working': 172,\n",
              " 'cant': 173,\n",
              " 'little': 174,\n",
              " 'long': 175,\n",
              " 'take': 176,\n",
              " 'wanna': 177,\n",
              " 'best': 178,\n",
              " 'first': 179,\n",
              " 'show': 180,\n",
              " 'his': 181,\n",
              " 'x': 182,\n",
              " 'who': 183,\n",
              " 'being': 184,\n",
              " 'please': 185,\n",
              " 'say': 186,\n",
              " 'having': 187,\n",
              " 'tired': 188,\n",
              " 'everyone': 189,\n",
              " 'life': 190,\n",
              " 'doing': 191,\n",
              " 'watch': 192,\n",
              " 'sick': 193,\n",
              " 'ok': 194,\n",
              " 'sure': 195,\n",
              " 'feeling': 196,\n",
              " 'our': 197,\n",
              " 'done': 198,\n",
              " 'thing': 199,\n",
              " 'any': 200,\n",
              " 'another': 201,\n",
              " '1': 202,\n",
              " 'something': 203,\n",
              " 'us': 204,\n",
              " 'already': 205,\n",
              " 'friends': 206,\n",
              " 'made': 207,\n",
              " 'find': 208,\n",
              " 'cool': 209,\n",
              " 'always': 210,\n",
              " 'where': 211,\n",
              " 'guys': 212,\n",
              " 'yay': 213,\n",
              " 'ly': 214,\n",
              " 'than': 215,\n",
              " 'ready': 216,\n",
              " 'looking': 217,\n",
              " 'yet': 218,\n",
              " 'because': 219,\n",
              " 'ur': 220,\n",
              " 'hours': 221,\n",
              " 'man': 222,\n",
              " 'house': 223,\n",
              " 'movie': 224,\n",
              " 'before': 225,\n",
              " 'p': 226,\n",
              " 'pretty': 227,\n",
              " 'phone': 228,\n",
              " 'went': 229,\n",
              " 'ever': 230,\n",
              " 'away': 231,\n",
              " 'tweet': 232,\n",
              " 'look': 233,\n",
              " 'maybe': 234,\n",
              " 'trying': 235,\n",
              " 'omg': 236,\n",
              " 'early': 237,\n",
              " '5': 238,\n",
              " 'help': 239,\n",
              " 'left': 240,\n",
              " 'finally': 241,\n",
              " 'into': 242,\n",
              " 'big': 243,\n",
              " 'old': 244,\n",
              " 'summer': 245,\n",
              " 'let': 246,\n",
              " 'amazing': 247,\n",
              " 'year': 248,\n",
              " 'damn': 249,\n",
              " 'keep': 250,\n",
              " 'follow': 251,\n",
              " 'same': 252,\n",
              " 'guess': 253,\n",
              " 'nothing': 254,\n",
              " 'rain': 255,\n",
              " 'missed': 256,\n",
              " 'lost': 257,\n",
              " 'sucks': 258,\n",
              " 'someone': 259,\n",
              " 'things': 260,\n",
              " 'wow': 261,\n",
              " 'bored': 262,\n",
              " 'hot': 263,\n",
              " 'girl': 264,\n",
              " 'coming': 265,\n",
              " 'friend': 266,\n",
              " 'also': 267,\n",
              " 'tell': 268,\n",
              " 'thought': 269,\n",
              " 'other': 270,\n",
              " 'try': 271,\n",
              " \"won't\": 272,\n",
              " 'baby': 273,\n",
              " 'n': 274,\n",
              " 'while': 275,\n",
              " 'later': 276,\n",
              " 'does': 277,\n",
              " 'looks': 278,\n",
              " 'live': 279,\n",
              " 'weather': 280,\n",
              " 'two': 281,\n",
              " 'glad': 282,\n",
              " \"doesn't\": 283,\n",
              " 'w': 284,\n",
              " 'birthday': 285,\n",
              " 'sun': 286,\n",
              " 'hard': 287,\n",
              " 'actually': 288,\n",
              " 'song': 289,\n",
              " 'hear': 290,\n",
              " 'start': 291,\n",
              " 'those': 292,\n",
              " 'ya': 293,\n",
              " 'stuff': 294,\n",
              " 'makes': 295,\n",
              " 'said': 296,\n",
              " 'ugh': 297,\n",
              " 'excited': 298,\n",
              " 'waiting': 299,\n",
              " 'myself': 300,\n",
              " 'game': 301,\n",
              " 'god': 302,\n",
              " 'might': 303,\n",
              " 'saw': 304,\n",
              " 'since': 305,\n",
              " 'yesterday': 306,\n",
              " 'party': 307,\n",
              " 'play': 308,\n",
              " 'few': 309,\n",
              " 'world': 310,\n",
              " 'many': 311,\n",
              " 'thats': 312,\n",
              " 'such': 313,\n",
              " 'until': 314,\n",
              " 'hi': 315,\n",
              " 'gotta': 316,\n",
              " 'around': 317,\n",
              " 'found': 318,\n",
              " 'car': 319,\n",
              " 'lot': 320,\n",
              " 'www': 321,\n",
              " 'sounds': 322,\n",
              " 'may': 323,\n",
              " 'give': 324,\n",
              " 'r': 325,\n",
              " 'call': 326,\n",
              " 'their': 327,\n",
              " \"he's\": 328,\n",
              " 'o': 329,\n",
              " 'beautiful': 330,\n",
              " \"haven't\": 331,\n",
              " 'aww': 332,\n",
              " 'late': 333,\n",
              " 'missing': 334,\n",
              " 'mom': 335,\n",
              " 'talk': 336,\n",
              " 'gone': 337,\n",
              " 'check': 338,\n",
              " 'music': 339,\n",
              " 'read': 340,\n",
              " 'monday': 341,\n",
              " 'head': 342,\n",
              " 'cold': 343,\n",
              " 'making': 344,\n",
              " 'luck': 345,\n",
              " 'tho': 346,\n",
              " 'woke': 347,\n",
              " 'must': 348,\n",
              " 'least': 349,\n",
              " 'job': 350,\n",
              " 'friday': 351,\n",
              " 'sunday': 352,\n",
              " 'put': 353,\n",
              " 'far': 354,\n",
              " 'times': 355,\n",
              " 'b': 356,\n",
              " 'anything': 357,\n",
              " 'food': 358,\n",
              " 'wanted': 359,\n",
              " 'almost': 360,\n",
              " 'use': 361,\n",
              " 'till': 362,\n",
              " 'listening': 363,\n",
              " 'poor': 364,\n",
              " 'leave': 365,\n",
              " 'iphone': 366,\n",
              " 'free': 367,\n",
              " 'most': 368,\n",
              " 'shit': 369,\n",
              " 'okay': 370,\n",
              " 'hour': 371,\n",
              " 'mean': 372,\n",
              " 'family': 373,\n",
              " \"isn't\": 374,\n",
              " 'finished': 375,\n",
              " 'cute': 376,\n",
              " 'everything': 377,\n",
              " 'hair': 378,\n",
              " 'enjoy': 379,\n",
              " 'dinner': 380,\n",
              " 'end': 381,\n",
              " 'stop': 382,\n",
              " 'gt': 383,\n",
              " 'hurts': 384,\n",
              " 'eat': 385,\n",
              " 'without': 386,\n",
              " 'followers': 387,\n",
              " 'anyone': 388,\n",
              " 'welcome': 389,\n",
              " 'd': 390,\n",
              " 'lunch': 391,\n",
              " 'funny': 392,\n",
              " 'sweet': 393,\n",
              " 'which': 394,\n",
              " '10': 395,\n",
              " 'believe': 396,\n",
              " 'playing': 397,\n",
              " '6': 398,\n",
              " 'tinyurl': 399,\n",
              " \"i'd\": 400,\n",
              " 'real': 401,\n",
              " 'forward': 402,\n",
              " 'thinking': 403,\n",
              " 'through': 404,\n",
              " 'hahaha': 405,\n",
              " 'mine': 406,\n",
              " 'outside': 407,\n",
              " 'wrong': 408,\n",
              " 'didnt': 409,\n",
              " 'plurk': 410,\n",
              " 'totally': 411,\n",
              " 'video': 412,\n",
              " 'buy': 413,\n",
              " 'enough': 414,\n",
              " 'coffee': 415,\n",
              " 'tv': 416,\n",
              " 't': 417,\n",
              " 'room': 418,\n",
              " 'ill': 419,\n",
              " 's': 420,\n",
              " 'these': 421,\n",
              " 'win': 422,\n",
              " 'probably': 423,\n",
              " 'anymore': 424,\n",
              " 'once': 425,\n",
              " 'stupid': 426,\n",
              " 'tweets': 427,\n",
              " 'money': 428,\n",
              " 'hopefully': 429,\n",
              " 'kinda': 430,\n",
              " 'eating': 431,\n",
              " 'whole': 432,\n",
              " 'following': 433,\n",
              " 'weeks': 434,\n",
              " 'wants': 435,\n",
              " 'cause': 436,\n",
              " 'ha': 437,\n",
              " 'place': 438,\n",
              " '30': 439,\n",
              " 'busy': 440,\n",
              " 'stay': 441,\n",
              " 'xx': 442,\n",
              " 'true': 443,\n",
              " 'awww': 444,\n",
              " 'every': 445,\n",
              " 'says': 446,\n",
              " 'pic': 447,\n",
              " \"we're\": 448,\n",
              " 'taking': 449,\n",
              " 'headache': 450,\n",
              " 'exam': 451,\n",
              " \"there's\": 452,\n",
              " 'saturday': 453,\n",
              " 'name': 454,\n",
              " 'crazy': 455,\n",
              " 'post': 456,\n",
              " 'came': 457,\n",
              " 'idea': 458,\n",
              " '8': 459,\n",
              " 'sooo': 460,\n",
              " \"she's\": 461,\n",
              " \"what's\": 462,\n",
              " 'both': 463,\n",
              " 'super': 464,\n",
              " 'kids': 465,\n",
              " 'years': 466,\n",
              " 'able': 467,\n",
              " 'lovely': 468,\n",
              " '7': 469,\n",
              " 'half': 470,\n",
              " 'rest': 471,\n",
              " 'took': 472,\n",
              " 'seen': 473,\n",
              " 'class': 474,\n",
              " \"wasn't\": 475,\n",
              " 'beach': 476,\n",
              " 'news': 477,\n",
              " 'boo': 478,\n",
              " 'hello': 479,\n",
              " 'goodnight': 480,\n",
              " 'leaving': 481,\n",
              " 'forgot': 482,\n",
              " 'guy': 483,\n",
              " 'trip': 484,\n",
              " 'office': 485,\n",
              " 'run': 486,\n",
              " 'meet': 487,\n",
              " 'face': 488,\n",
              " 'seems': 489,\n",
              " 'dad': 490,\n",
              " 'either': 491,\n",
              " 'sitting': 492,\n",
              " 'else': 493,\n",
              " 'book': 494,\n",
              " 'shopping': 495,\n",
              " 'reading': 496,\n",
              " 'heart': 497,\n",
              " 'hurt': 498,\n",
              " 'lots': 499,\n",
              " 'hell': 500,\n",
              " 'fuck': 501,\n",
              " 'send': 502,\n",
              " \"they're\": 503,\n",
              " 'feels': 504,\n",
              " 'watched': 505,\n",
              " 'full': 506,\n",
              " 'computer': 507,\n",
              " 'remember': 508,\n",
              " 'needs': 509,\n",
              " 'alone': 510,\n",
              " 'kind': 511,\n",
              " 'ah': 512,\n",
              " 'blog': 513,\n",
              " 'tried': 514,\n",
              " 'used': 515,\n",
              " 'cuz': 516,\n",
              " 'mileycyrus': 517,\n",
              " 'c': 518,\n",
              " 'raining': 519,\n",
              " 'talking': 520,\n",
              " 'course': 521,\n",
              " 'heard': 522,\n",
              " 'hit': 523,\n",
              " 'ago': 524,\n",
              " 'btw': 525,\n",
              " 'facebook': 526,\n",
              " 'seeing': 527,\n",
              " 'girls': 528,\n",
              " 'soo': 529,\n",
              " 'own': 530,\n",
              " 'hehe': 531,\n",
              " 'mind': 532,\n",
              " 'boy': 533,\n",
              " 'care': 534,\n",
              " 'pics': 535,\n",
              " 'internet': 536,\n",
              " 'told': 537,\n",
              " 'dog': 538,\n",
              " 'online': 539,\n",
              " 'stuck': 540,\n",
              " 'part': 541,\n",
              " \"couldn't\": 542,\n",
              " 'loved': 543,\n",
              " 'using': 544,\n",
              " 'breakfast': 545,\n",
              " 'change': 546,\n",
              " 'fine': 547,\n",
              " 'boring': 548,\n",
              " 'instead': 549,\n",
              " 'site': 550,\n",
              " 'la': 551,\n",
              " 'started': 552,\n",
              " 'pain': 553,\n",
              " 'dude': 554,\n",
              " 'lucky': 555,\n",
              " 'wont': 556,\n",
              " 'quite': 557,\n",
              " 'season': 558,\n",
              " 'picture': 559,\n",
              " 'asleep': 560,\n",
              " 'lmao': 561,\n",
              " 'open': 562,\n",
              " 'ass': 563,\n",
              " '9': 564,\n",
              " 'wake': 565,\n",
              " 'add': 566,\n",
              " 'person': 567,\n",
              " 'update': 568,\n",
              " 'til': 569,\n",
              " 'anyway': 570,\n",
              " 'seriously': 571,\n",
              " 'm': 572,\n",
              " \"you'll\": 573,\n",
              " 'goes': 574,\n",
              " 'cry': 575,\n",
              " 'fan': 576,\n",
              " 'called': 577,\n",
              " 'break': 578,\n",
              " 'e': 579,\n",
              " 'ice': 580,\n",
              " 'reply': 581,\n",
              " 'bring': 582,\n",
              " 'awake': 583,\n",
              " 'drive': 584,\n",
              " 'crap': 585,\n",
              " 'walk': 586,\n",
              " 'minutes': 587,\n",
              " 'hoping': 588,\n",
              " 'xd': 589,\n",
              " 'sunny': 590,\n",
              " 'mad': 591,\n",
              " 'concert': 592,\n",
              " 'sometimes': 593,\n",
              " 'broke': 594,\n",
              " 'heading': 595,\n",
              " 'bye': 596,\n",
              " 'enjoying': 597,\n",
              " 'favorite': 598,\n",
              " 'june': 599,\n",
              " 'hungry': 600,\n",
              " 'text': 601,\n",
              " 'yea': 602,\n",
              " 'died': 603,\n",
              " 'youtube': 604,\n",
              " 'exams': 605,\n",
              " 'gets': 606,\n",
              " 'link': 607,\n",
              " '0': 608,\n",
              " 'aw': 609,\n",
              " 'afternoon': 610,\n",
              " 'sore': 611,\n",
              " 'problem': 612,\n",
              " 'bought': 613,\n",
              " 'pay': 614,\n",
              " 'month': 615,\n",
              " 'study': 616,\n",
              " 'running': 617,\n",
              " 'starting': 618,\n",
              " 'together': 619,\n",
              " 'definitely': 620,\n",
              " 'means': 621,\n",
              " 'write': 622,\n",
              " 'rock': 623,\n",
              " 'move': 624,\n",
              " 'sigh': 625,\n",
              " 'ask': 626,\n",
              " '100': 627,\n",
              " 'happened': 628,\n",
              " 'album': 629,\n",
              " 'loves': 630,\n",
              " 'works': 631,\n",
              " 'red': 632,\n",
              " 'church': 633,\n",
              " \"we'll\": 634,\n",
              " 'tommcfly': 635,\n",
              " 'sleeping': 636,\n",
              " 'wonderful': 637,\n",
              " 'brother': 638,\n",
              " 'train': 639,\n",
              " 'dead': 640,\n",
              " 'jealous': 641,\n",
              " 'eyes': 642,\n",
              " 'congrats': 643,\n",
              " 'finish': 644,\n",
              " '12': 645,\n",
              " 'town': 646,\n",
              " 'suck': 647,\n",
              " 'fail': 648,\n",
              " 'reason': 649,\n",
              " 'email': 650,\n",
              " 'dear': 651,\n",
              " 'fucking': 652,\n",
              " 'homework': 653,\n",
              " 'tour': 654,\n",
              " 'soooo': 655,\n",
              " 'shower': 656,\n",
              " 'drink': 657,\n",
              " 'cream': 658,\n",
              " 'high': 659,\n",
              " 'laptop': 660,\n",
              " 'cut': 661,\n",
              " 'ipod': 662,\n",
              " 'ive': 663,\n",
              " 'comes': 664,\n",
              " 'water': 665,\n",
              " 'bout': 666,\n",
              " 'happen': 667,\n",
              " 'fall': 668,\n",
              " 'couple': 669,\n",
              " 'tickets': 670,\n",
              " 'ppl': 671,\n",
              " 'city': 672,\n",
              " 'sister': 673,\n",
              " 'boys': 674,\n",
              " 'less': 675,\n",
              " 'studying': 676,\n",
              " 'fm': 677,\n",
              " 'mood': 678,\n",
              " 'interesting': 679,\n",
              " 'months': 680,\n",
              " 'hang': 681,\n",
              " 'nap': 682,\n",
              " 'english': 683,\n",
              " 'star': 684,\n",
              " 'seem': 685,\n",
              " 'ddlovato': 686,\n",
              " 'top': 687,\n",
              " 'dream': 688,\n",
              " 'side': 689,\n",
              " 'loving': 690,\n",
              " 'won': 691,\n",
              " 'test': 692,\n",
              " 'catch': 693,\n",
              " 'word': 694,\n",
              " 'movies': 695,\n",
              " 'weird': 696,\n",
              " 'tea': 697,\n",
              " 'cat': 698,\n",
              " 'songs': 699,\n",
              " 'fast': 700,\n",
              " 'listen': 701,\n",
              " 'l': 702,\n",
              " 'gym': 703,\n",
              " 'short': 704,\n",
              " 'ate': 705,\n",
              " 'moment': 706,\n",
              " 'uk': 707,\n",
              " 'perfect': 708,\n",
              " 'evening': 709,\n",
              " 'driving': 710,\n",
              " 'sunshine': 711,\n",
              " 'ones': 712,\n",
              " 'turn': 713,\n",
              " 'awards': 714,\n",
              " 'broken': 715,\n",
              " 'goin': 716,\n",
              " 'fb': 717,\n",
              " 'knew': 718,\n",
              " 'set': 719,\n",
              " 'list': 720,\n",
              " 'myspace': 721,\n",
              " 'meeting': 722,\n",
              " 'final': 723,\n",
              " 'story': 724,\n",
              " 'dance': 725,\n",
              " 'visit': 726,\n",
              " 'second': 727,\n",
              " 'close': 728,\n",
              " 'clean': 729,\n",
              " 'y': 730,\n",
              " 'lil': 731,\n",
              " 'worst': 732,\n",
              " '20': 733,\n",
              " 'sound': 734,\n",
              " 'nite': 735,\n",
              " 'cleaning': 736,\n",
              " 'tweeting': 737,\n",
              " 'sleepy': 738,\n",
              " 'wedding': 739,\n",
              " 'writing': 740,\n",
              " 'blip': 741,\n",
              " 'park': 742,\n",
              " 're': 743,\n",
              " 'moving': 744,\n",
              " '11': 745,\n",
              " 'wishing': 746,\n",
              " 'store': 747,\n",
              " 'green': 748,\n",
              " 'mr': 749,\n",
              " 'yep': 750,\n",
              " 'ride': 751,\n",
              " 'forget': 752,\n",
              " 'point': 753,\n",
              " 'unfortunately': 754,\n",
              " 'supposed': 755,\n",
              " 'chocolate': 756,\n",
              " 'lady': 757,\n",
              " 'david': 758,\n",
              " 'page': 759,\n",
              " 'mac': 760,\n",
              " 'hmm': 761,\n",
              " 'past': 762,\n",
              " 'plan': 763,\n",
              " 'date': 764,\n",
              " 'followfriday': 765,\n",
              " 'agree': 766,\n",
              " 'wonder': 767,\n",
              " 'worth': 768,\n",
              " 'via': 769,\n",
              " 'gave': 770,\n",
              " 'smile': 771,\n",
              " 'london': 772,\n",
              " 'hugs': 773,\n",
              " \"let's\": 774,\n",
              " 'drinking': 775,\n",
              " \"'\": 776,\n",
              " 'sent': 777,\n",
              " '1st': 778,\n",
              " 'throat': 779,\n",
              " 'whats': 780,\n",
              " 'chance': 781,\n",
              " 'pictures': 782,\n",
              " 'pick': 783,\n",
              " 'xxx': 784,\n",
              " 'saying': 785,\n",
              " 'pool': 786,\n",
              " 'lazy': 787,\n",
              " 'fell': 788,\n",
              " 'parents': 789,\n",
              " 'upset': 790,\n",
              " 'account': 791,\n",
              " 'words': 792,\n",
              " 'easy': 793,\n",
              " 'black': 794,\n",
              " 'ahh': 795,\n",
              " 'horrible': 796,\n",
              " 'bet': 797,\n",
              " 'ahhh': 798,\n",
              " 'photo': 799,\n",
              " 'slow': 800,\n",
              " 'due': 801,\n",
              " 'jonas': 802,\n",
              " 'k': 803,\n",
              " 'flu': 804,\n",
              " 'updates': 805,\n",
              " '15': 806,\n",
              " 'three': 807,\n",
              " 'worse': 808,\n",
              " 'plus': 809,\n",
              " 'doesnt': 810,\n",
              " 'air': 811,\n",
              " 'body': 812,\n",
              " 'vote': 813,\n",
              " 'wtf': 814,\n",
              " 'miley': 815,\n",
              " 'earlier': 816,\n",
              " 'line': 817,\n",
              " 'moon': 818,\n",
              " 'team': 819,\n",
              " 'mtv': 820,\n",
              " 'nope': 821,\n",
              " \"wouldn't\": 822,\n",
              " 'sat': 823,\n",
              " 'under': 824,\n",
              " 'scared': 825,\n",
              " 'understand': 826,\n",
              " 'longer': 827,\n",
              " 'da': 828,\n",
              " 'flight': 829,\n",
              " 'cannot': 830,\n",
              " 'dreams': 831,\n",
              " 'wondering': 832,\n",
              " 'holiday': 833,\n",
              " 'tuesday': 834,\n",
              " 'learn': 835,\n",
              " 'lets': 836,\n",
              " 'thx': 837,\n",
              " 'white': 838,\n",
              " 'plans': 839,\n",
              " 'apparently': 840,\n",
              " 'mum': 841,\n",
              " 'especially': 842,\n",
              " 'join': 843,\n",
              " 'warm': 844,\n",
              " 'camera': 845,\n",
              " 'fair': 846,\n",
              " 'slept': 847,\n",
              " 'special': 848,\n",
              " 'huge': 849,\n",
              " 'shows': 850,\n",
              " 'website': 851,\n",
              " 'during': 852,\n",
              " 'idk': 853,\n",
              " 'hand': 854,\n",
              " 'fans': 855,\n",
              " 'thinks': 856,\n",
              " 'forever': 857,\n",
              " 'twilight': 858,\n",
              " 'hanging': 859,\n",
              " 'rather': 860,\n",
              " 'vacation': 861,\n",
              " 'radio': 862,\n",
              " 'photos': 863,\n",
              " 'rainy': 864,\n",
              " 'shame': 865,\n",
              " 'bus': 866,\n",
              " 'college': 867,\n",
              " 'needed': 868,\n",
              " 'spent': 869,\n",
              " 'bday': 870,\n",
              " 'meant': 871,\n",
              " 'different': 872,\n",
              " 'cake': 873,\n",
              " 'july': 874,\n",
              " 'beer': 875,\n",
              " \"aren't\": 876,\n",
              " 'looked': 877,\n",
              " '2day': 878,\n",
              " 'luv': 879,\n",
              " 'dress': 880,\n",
              " 'worry': 881,\n",
              " 'yummy': 882,\n",
              " 'paper': 883,\n",
              " 'pizza': 884,\n",
              " \"you've\": 885,\n",
              " 'officially': 886,\n",
              " 'graduation': 887,\n",
              " 'fix': 888,\n",
              " 'message': 889,\n",
              " 'number': 890,\n",
              " 'power': 891,\n",
              " 'keeps': 892,\n",
              " 'small': 893,\n",
              " 'crying': 894,\n",
              " 'voice': 895,\n",
              " 'support': 896,\n",
              " 'chat': 897,\n",
              " 'band': 898,\n",
              " 'google': 899,\n",
              " 'bbq': 900,\n",
              " 'babe': 901,\n",
              " 'kill': 902,\n",
              " 'answer': 903,\n",
              " 'shop': 904,\n",
              " 'spend': 905,\n",
              " 'tummy': 906,\n",
              " 'stomach': 907,\n",
              " 'project': 908,\n",
              " 'tom': 909,\n",
              " 'garden': 910,\n",
              " 'decided': 911,\n",
              " 'felt': 912,\n",
              " 'ff': 913,\n",
              " 'packing': 914,\n",
              " 'sadly': 915,\n",
              " 'episode': 916,\n",
              " \"it'll\": 917,\n",
              " 'worked': 918,\n",
              " 'shall': 919,\n",
              " 'yourself': 920,\n",
              " 'xoxo': 921,\n",
              " 'woo': 922,\n",
              " 'gorgeous': 923,\n",
              " 'die': 924,\n",
              " 'laugh': 925,\n",
              " 'proud': 926,\n",
              " 'wear': 927,\n",
              " 'shoes': 928,\n",
              " 'jonasbrothers': 929,\n",
              " 'v': 930,\n",
              " 'sims': 931,\n",
              " 'bro': 932,\n",
              " 'hates': 933,\n",
              " \"mother's\": 934,\n",
              " 'blue': 935,\n",
              " 'save': 936,\n",
              " 'annoying': 937,\n",
              " 'inside': 938,\n",
              " 'played': 939,\n",
              " 'apple': 940,\n",
              " 'shirt': 941,\n",
              " 'hug': 942,\n",
              " 'airport': 943,\n",
              " 'chicken': 944,\n",
              " 'books': 945,\n",
              " 'liked': 946,\n",
              " 'share': 947,\n",
              " 'hospital': 948,\n",
              " 'each': 949,\n",
              " 'starts': 950,\n",
              " 'j': 951,\n",
              " 'finals': 952,\n",
              " 'everybody': 953,\n",
              " 'feet': 954,\n",
              " 'mothers': 955,\n",
              " 'thursday': 956,\n",
              " 'yup': 957,\n",
              " 'ouch': 958,\n",
              " 'living': 959,\n",
              " 'figure': 960,\n",
              " 'minute': 961,\n",
              " 'met': 962,\n",
              " 'havent': 963,\n",
              " 'hmmm': 964,\n",
              " 'road': 965,\n",
              " 'fact': 966,\n",
              " 'safe': 967,\n",
              " 'business': 968,\n",
              " 'wednesday': 969,\n",
              " 'games': 970,\n",
              " 'death': 971,\n",
              " 'except': 972,\n",
              " 'exciting': 973,\n",
              " 'eye': 974,\n",
              " 'alright': 975,\n",
              " 'absolutely': 976,\n",
              " 'lame': 977,\n",
              " 'brothers': 978,\n",
              " 'jus': 979,\n",
              " 'wit': 980,\n",
              " 'sign': 981,\n",
              " 'wishes': 982,\n",
              " 'dm': 983,\n",
              " 'wine': 984,\n",
              " 'isnt': 985,\n",
              " 'kid': 986,\n",
              " 'beat': 987,\n",
              " 'bike': 988,\n",
              " 'goodbye': 989,\n",
              " 'single': 990,\n",
              " 'case': 991,\n",
              " 'peace': 992,\n",
              " 'card': 993,\n",
              " 'boyfriend': 994,\n",
              " 'self': 995,\n",
              " 'club': 996,\n",
              " 'dying': 997,\n",
              " 'sit': 998,\n",
              " 'happens': 999,\n",
              " 'enjoyed': 1000,\n",
              " ...}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gIrtRem1En3N",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "e69b2c51-2197-455b-9a55-cec08784125e"
      },
      "source": [
        "print(vocab_size)\n",
        "print(word_index['i'])\n",
        "# Expected Output\n",
        "# 138858\n",
        "# 1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "138359\n",
            "2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "C1zdgJkusRh0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "e32d09b8-6b9b-410d-a369-2f018807a198"
      },
      "source": [
        "# Note this is the 100 dimension version of GloVe from Stanford\n",
        "# I unzipped and hosted it on my site to make this notebook easier\n",
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/laurencemoroney-blog.appspot.com/glove.6B.100d.txt \\\n",
        "    -O /tmp/glove.6B.100d.txt\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-07-23 23:06:07--  https://storage.googleapis.com/laurencemoroney-blog.appspot.com/glove.6B.100d.txt\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 173.194.69.128, 108.177.119.128, 108.177.126.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|173.194.69.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 347116733 (331M) [text/plain]\n",
            "Saving to: ‘/tmp/glove.6B.100d.txt’\n",
            "\n",
            "/tmp/glove.6B.100d. 100%[===================>] 331.04M   119MB/s    in 2.8s    \n",
            "\n",
            "2020-07-23 23:06:10 (119 MB/s) - ‘/tmp/glove.6B.100d.txt’ saved [347116733/347116733]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eSYJZ2FWK4Mo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0497cb9c-5369-4a4d-da44-3a2d413a8a36"
      },
      "source": [
        "embeddings_index = {}\n",
        "with open('/tmp/glove.6B.100d.txt') as f:\n",
        "    for line in f:\n",
        "        values = line.split( )\n",
        "        word = values[0];\n",
        "        coefs = np.asarray(values[1:], dtype='float32');\n",
        "        embeddings_index[word] = coefs;\n",
        "count=0\n",
        "embeddings_matrix = np.zeros((vocab_size+1, embedding_dim));\n",
        "for word, i in word_index.items():\n",
        "    embedding_vector = embeddings_index.get(word);\n",
        "    if embedding_vector is not None:\n",
        "        embeddings_matrix[i] = embedding_vector;\n",
        "    else:\n",
        "      count+=1\n",
        "print(count)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "95145\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qn_IYo2hqwjd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "d88cb5bb-f1ed-49d0-f0c4-bab5358e6eaa"
      },
      "source": [
        "embeddings_matrix[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "71NLk_lpFLNt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0e3ea1a1-84a2-43b9-cd28-52b3e586816c"
      },
      "source": [
        "print(len(embeddings_matrix))\n",
        "# Expected Output\n",
        "# 138859"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "138360\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6bIDGALKdtdU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "eedcc0b1-b527-413d-f4c6-ab2db464bdce"
      },
      "source": [
        "embeddings_matrix.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(138360, 100)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ONp41Co3-uL9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "9f99b5f5-834a-40b8-8659-f660265454f3"
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(vocab_size+1,embedding_dim, input_length=max_length, weights=[embeddings_matrix], trainable=False),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Conv1D(128,5,activation=\"relu\"),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    #tf.keras.layers.Conv1D(128,5,activation=\"relu\"),\n",
        "   # tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.GlobalMaxPooling1D(),\n",
        "    #tf.keras.layers.MaxPooling1D( pool_size=4),\n",
        "    #tf.keras.layers.Flatten(),\n",
        "    #\n",
        "    #\n",
        "    #tf.keras.layers.Conv1D(64,5,activation=\"relu\"),\n",
        "    \n",
        "    #tf.keras.layers.GlobalMaxPooling1D(),\n",
        "    #tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Dense(32,activation=\"relu\"),\n",
        "    \n",
        "    tf.keras.layers.Dense(1,activation=\"sigmoid\")\n",
        "])\n",
        "model.compile(optimizer=\"adam\" ,loss=\"binary_crossentropy\",metrics=[\"accuracy\"])\n",
        "model.summary()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_4 (Embedding)      (None, 16, 100)           13836000  \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 16, 100)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 12, 128)           64128     \n",
            "_________________________________________________________________\n",
            "dropout_9 (Dropout)          (None, 12, 128)           0         \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d_2 (Glob (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 32)                4128      \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 13,904,289\n",
            "Trainable params: 68,289\n",
            "Non-trainable params: 13,836,000\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DOKguH-Ir2oo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "45f75c4f-b8d8-4c1c-ae38-eece744795bc"
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(vocab_size+1,embedding_dim, input_length=max_length, weights=[embeddings_matrix], trainable=True),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    #tf.keras.layers.Embedding(vocab_size+1,embedding_dim, input_length=max_length),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    #tf.keras.layers.Flatten(),\n",
        "    #tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),\n",
        "    \n",
        "    #tf.keras.layers.Conv1D(128,5,activation=\"relu\"),\n",
        "    #tf.keras.layers.GlobalMaxPooling1D(),\n",
        "    \n",
        "    tf.keras.layers.Dense(32,activation=\"relu\"),\n",
        "    \n",
        "    tf.keras.layers.Dense(1,activation=\"sigmoid\")\n",
        "])\n",
        "model.compile(optimizer=\"adam\" ,loss=\"binary_crossentropy\",metrics=[\"accuracy\"])\n",
        "model.summary()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_3 (Embedding)      (None, 16, 100)           13836000  \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 16, 100)           0         \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, 128)               84480     \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 32)                4128      \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 13,924,641\n",
            "Trainable params: 13,924,641\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "iKKvbuEBOGFz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "outputId": "9af87391-32a5-445a-9c8a-d5a9b293707f"
      },
      "source": [
        "num_epochs = 2\n",
        "history = model.fit(training_sequences, training_labels, epochs=num_epochs, validation_data=(test_sequences, test_labels), verbose=1)\n",
        "\n",
        "print(\"Training Complete\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            " 174/4500 [>.............................] - ETA: 9:03 - loss: 0.6462 - accuracy: 0.6245"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-48-5cce961cffc2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_sequences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_sequences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training Complete\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    846\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m    847\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 848\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    849\u001b[0m               \u001b[0;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m               \u001b[0;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    609\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    612\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2418\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2420\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2422\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1664\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1665\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1667\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9fjEWlJ0ZIeJ",
        "colab_type": "text"
      },
      "source": [
        "## LSTM con dropout\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qxju4ItJKO8F",
        "colab": {}
      },
      "source": [
        "import matplotlib.image  as mpimg\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#-----------------------------------------------------------\n",
        "# Retrieve a list of list results on training and test data\n",
        "# sets for each training epoch\n",
        "#-----------------------------------------------------------\n",
        "acc=history.history['accuracy']\n",
        "val_acc=history.history['val_accuracy']\n",
        "loss=history.history['loss']\n",
        "val_loss=history.history['val_loss']\n",
        "\n",
        "epochs=range(len(acc)) # Get number of epochs\n",
        "\n",
        "#------------------------------------------------\n",
        "# Plot training and validation accuracy per epoch\n",
        "#------------------------------------------------\n",
        "plt.plot(epochs, acc, 'r')\n",
        "plt.plot(epochs, val_acc, 'b')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend([\"Accuracy\", \"Validation Accuracy\"])\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "#------------------------------------------------\n",
        "# Plot training and validation loss per epoch\n",
        "#------------------------------------------------\n",
        "plt.plot(epochs, loss, 'r')\n",
        "plt.plot(epochs, val_loss, 'b')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend([\"Loss\", \"Validation Loss\"])\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "\n",
        "# Expected Output\n",
        "# A chart where the validation loss does not increase sharply!"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0k0fCTmDZOWX",
        "colab_type": "text"
      },
      "source": [
        "## convolucion con dropout"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XAu2LBcdv_-L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.image  as mpimg\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#-----------------------------------------------------------\n",
        "# Retrieve a list of list results on training and test data\n",
        "# sets for each training epoch\n",
        "#-----------------------------------------------------------\n",
        "acc=history.history['accuracy']\n",
        "val_acc=history.history['val_accuracy']\n",
        "loss=history.history['loss']\n",
        "val_loss=history.history['val_loss']\n",
        "\n",
        "epochs=range(len(acc)) # Get number of epochs\n",
        "\n",
        "#------------------------------------------------\n",
        "# Plot training and validation accuracy per epoch\n",
        "#------------------------------------------------\n",
        "plt.plot(epochs, acc, 'r')\n",
        "plt.plot(epochs, val_acc, 'b')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend([\"Accuracy\", \"Validation Accuracy\"])\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "#------------------------------------------------\n",
        "# Plot training and validation loss per epoch\n",
        "#------------------------------------------------\n",
        "plt.plot(epochs, loss, 'r')\n",
        "plt.plot(epochs, val_loss, 'b')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend([\"Loss\", \"Validation Loss\"])\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "\n",
        "# Expected Output\n",
        "# A chart where the validation loss does not increase sharply!"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gRxwvyOxZrqJ",
        "colab_type": "text"
      },
      "source": [
        "## con convolución"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "547xB8lQZt92",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.image  as mpimg\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#-----------------------------------------------------------\n",
        "# Retrieve a list of list results on training and test data\n",
        "# sets for each training epoch\n",
        "#-----------------------------------------------------------\n",
        "acc=history.history['accuracy']\n",
        "val_acc=history.history['val_accuracy']\n",
        "loss=history.history['loss']\n",
        "val_loss=history.history['val_loss']\n",
        "\n",
        "epochs=range(len(acc)) # Get number of epochs\n",
        "\n",
        "#------------------------------------------------\n",
        "# Plot training and validation accuracy per epoch\n",
        "#------------------------------------------------\n",
        "plt.plot(epochs, acc, 'r')\n",
        "plt.plot(epochs, val_acc, 'b')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend([\"Accuracy\", \"Validation Accuracy\"])\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "#------------------------------------------------\n",
        "# Plot training and validation loss per epoch\n",
        "#------------------------------------------------\n",
        "plt.plot(epochs, loss, 'r')\n",
        "plt.plot(epochs, val_loss, 'b')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend([\"Loss\", \"Validation Loss\"])\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "\n",
        "# Expected Output\n",
        "# A chart where the validation loss does not increase sharply!"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lVLp-1qWkvwz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.random.set_seed(0)\n",
        "layer = tf.keras.layers.Dropout(.2,noise_shape=(5, 4, 1))\n",
        "data = np.arange(120).reshape(5,4,6).astype(np.float32)\n",
        "print(data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A1MNcYLMMtOm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "outputs = layer(data, training=True)\n",
        "print(outputs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7QLTUgumMvRf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "array=np.arange(25).reshape(5,5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RicqzekUNHIO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "array[:,:-1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m3s25tSgNcRC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "array"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dZfDmQxRNpcK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "labels=[8,4,5,5,7,3,9,1]\n",
        "tf.keras.utils.to_categorical(labels, num_classes=15)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fZAutJ6doMXf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}